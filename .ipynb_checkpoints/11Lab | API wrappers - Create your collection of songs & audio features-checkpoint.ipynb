{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "geographic-sword",
   "metadata": {},
   "source": [
    "## Tell me a song, \n",
    "## I will tell you if it is hot, \n",
    "## if not I will recomend you a similar song.\n",
    "\n",
    "![Pokemon](images/spotify.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-burke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "medieval-louisiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a song : bad romance\n",
      "Right now it is not a hot song, so tell my the link of a playlist,\n",
      "I'll recomend you a song based on this playlist,\n",
      "it will take me a few moments : https://open.spotify.com/playlist/5XbnEtKOWl1c2GwfY1bnN8?si=03577c741a7f4de0\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ce2253128392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-31b03bda8e75>\u001b[0m in \u001b[0;36mcheck\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0muser_song_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_song_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'uri'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'track_href'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'analysis_url'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0muser_song_feat_sca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_song_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0muser_clus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_song_feat_sca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \"\"\"\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-lawrence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-bailey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-table",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-finger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link of an exaple play list (with 13 songs it takes like 15 mins to run it).\n",
    "'https://open.spotify.com/playlist/5XbnEtKOWl1c2GwfY1bnN8?si=03577c741a7f4de0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-messenger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-press",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-munich",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "indonesian-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Fuction.\n",
    "def check():\n",
    "        selected_song = input(str('Tell me a song : ')).title()\n",
    "        if selected_song in songs['title'].values:  \n",
    "            recomendation = songs.sample()\n",
    "            print('It is in the list, probaly you will like',recomendation['title'].values[0], 'from',recomendation['artist'].values[0])\n",
    "        else: \n",
    "            link = input(\"Right now it is not a hot song, so tell my the link of a playlist,\\n\" \n",
    "                         \"I'll recomend you a song based on this playlist,\\n\"\n",
    "                         \"it will take me a few moments : \")\n",
    "            code = re.findall('\\w{20,25}', str(link))\n",
    "            playlist = sp.user_playlist_tracks(\"spotify\", code[0])\n",
    "            playlist_more_song_features(playlist)\n",
    "            uri = sp.search(q=selected_song)['tracks']['items'][0]['uri']\n",
    "            user_song_feat = sp.audio_features(uri)\n",
    "            user_song_feat = pd.DataFrame(user_song_feat).drop(['id','uri','track_href','analysis_url','type'],axis=1)\n",
    "            scale = StandardScaler()\n",
    "            user_song_feat_sca = scale.transform(user_song_feat)\n",
    "            user_clus = kmeans.predict(user_song_feat_sca)  \n",
    "            \n",
    "            recomendation = (song_clusters[song_clusters['cluster'] == user_clus[0]]).sample()\n",
    "            \n",
    "            print('Probably you will like ',\n",
    "                  (recomendation['song'].values)[0],\n",
    "                 'from ', (recomendation['artists'].values)[0],\"enjoy it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-klein",
   "metadata": {},
   "source": [
    "### 1.Getting all libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "smaller-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-ghana",
   "metadata": {},
   "source": [
    "### 2. Web scraping to have a data set of top songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "innovative-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.billboard.com/charts/hot-100'\n",
    "response = requests.get(url)\n",
    "response.status_code\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# To generate the data frame of all top songs.\n",
    "num_itr = len(soup.select('span.chart-element__information > span.chart-element__information__song.text--truncate.color--primary'))\n",
    "\n",
    "rank = []\n",
    "title = []\n",
    "art = []\n",
    "\n",
    "for song in range(num_itr):\n",
    "    title.append(soup.select('span.chart-element__information__song')[song].get_text())\n",
    "    art.append(soup.select('span.chart-element__information__artist')[song].get_text())\n",
    "    rank.append(soup.select('span.chart-element__rank__number')[song].get_text())\n",
    "songs = pd.DataFrame({\"ranking\":rank, \"title\":title, \"artist\":art})  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-injection",
   "metadata": {},
   "source": [
    "### 3. Create a collection of songs with their audio features, depending on a link to give the recomendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "accessory-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets_file = open(\"../../spotify_user.txt\",\"r\")\n",
    "string = secrets_file.read()\n",
    "string.split('\\n')\n",
    "secrets_dict={}\n",
    "for line in string.split('\\n'):\n",
    "  secrets_dict[line.split(':')[0]]=line.split(':')[1]\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=secrets_dict['client_id'],\n",
    "                                                           client_secret=secrets_dict['client_secret']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "vanilla-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlist_more_song_features(playlist):    \n",
    "    songs = get_name_artists_from_playlist(playlist) \n",
    "\n",
    "    # In order to get all the singers in a list.\n",
    "    singers = []\n",
    "    for i in range(len(songs)):             \n",
    "        singers.append(songs[i][1])\n",
    "\n",
    "    singers = list(dict.fromkeys(singers))  #To drop duplicates singers\n",
    "\n",
    "    # Itereting with the previous fuction, we have names of more songs in a list\n",
    "    more_songs = []   \n",
    "    for i in range(len(singers)):  \n",
    "        more_songs.append(get_artist_tracks(singers[i]))\n",
    "\n",
    "    more_songs = flatten(more_songs)  # To have it in a singel list\n",
    "\n",
    "    songs_names = []\n",
    "    artists_names = []\n",
    "    uris = []\n",
    "\n",
    "    # To have the songs and artists names and features\n",
    "    for track in more_songs:\n",
    "        songs_names.append(track['name'])\n",
    "        artists_names.append(track['artists'][0]['name'])\n",
    "\n",
    "    i = 0\n",
    "    chunk_of_100_uris = []\n",
    "    for track in more_songs:\n",
    "        if i < 100:\n",
    "            chunk_of_100_uris.append(sp.audio_features(track['uri']))\n",
    "            i = i+1\n",
    "        else:\n",
    "            uris.append(chunk_of_100_uris)\n",
    "            i = 0\n",
    "            chunk_of_100_uris = []\n",
    "            chunk_of_100_uris.append(sp.audio_features(track['uri']))\n",
    "            i = i+1       \n",
    "    uris.append(chunk_of_100_uris)   \n",
    "\n",
    "    uris = flatten(flatten(uris))  # To have a unique list\n",
    "\n",
    "    #Creating the data Frame\n",
    "    S = pd.DataFrame(songs_names)\n",
    "    A = pd.DataFrame(artists_names)\n",
    "    U = pd.DataFrame(uris)\n",
    "\n",
    "    S.columns = ['song']\n",
    "    A.columns = ['artists']\n",
    "\n",
    "    SAU = pd.concat([S,A,U],axis=1)\n",
    "    SAU = SAU.drop(['id','uri','track_href','analysis_url','type'],axis=1)\n",
    "\n",
    "\n",
    "    #Spliting the data frame\n",
    "    SAU_name = SAU[['song','artists']]\n",
    "    SAU_features = SAU.drop(['song','artists'],axis=1)\n",
    "\n",
    "    # Normalizing it.\n",
    "    scale = StandardScaler()\n",
    "    X_prep = scale.fit_transform(SAU_features)\n",
    "\n",
    "    # The prediction model.\n",
    "    kmeans = KMeans(n_clusters=12, random_state=1234)\n",
    "    kmeans.fit(X_prep)\n",
    "\n",
    "    # Predicting / assigning the clusters:\n",
    "    clusters = kmeans.predict(X_prep)\n",
    "\n",
    "    #Finall data frame\n",
    "    clusters = pd.DataFrame(clusters, columns = ['cluster'])\n",
    "    SAU_features_stand = pd.DataFrame(X_prep,columns = SAU_features.columns)\n",
    "    song_clusters = pd.concat([clusters,SAU_name,SAU_features_stand],axis=1)\n",
    "    song_clusters = song_clusters.drop_duplicates(['song','artists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-attack",
   "metadata": {},
   "source": [
    "### 4. Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hundred-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_artists_from_track(track):\n",
    "    return [(track[\"name\"],track['artists'][0]['name'])]\n",
    "\n",
    "def get_name_artist_from_playlist_item(playlist_item):\n",
    "      return get_name_artists_from_track(playlist_item['track'])\n",
    "    \n",
    "def flatten(input_list):\n",
    "      return [item for sublist in input_list for item in sublist]\n",
    "    \n",
    "def get_name_artists_from_playlist(input_playlist):\n",
    "      return flatten(list(map(get_name_artist_from_playlist_item,input_playlist[\"items\"])))\n",
    "    \n",
    "# Defining a fuction to be able to get 950 songs of each singer in the previous list.\n",
    "def get_artist_tracks(artist):  \n",
    "    results = sp.search(q=artist,limit=50)\n",
    "    tracks = results['tracks']['items']\n",
    "    i=0\n",
    "    while ((results['tracks']['next']!=None)) & (i<19):\n",
    "        i = i+1\n",
    "        results = sp.next(results['tracks'])\n",
    "        tracks = tracks + results['tracks']['items']\n",
    "    return tracks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
